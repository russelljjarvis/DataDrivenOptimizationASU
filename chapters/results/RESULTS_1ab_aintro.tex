
\section{Limitations of Optimization using Experimental Data}
\label{sec:limitations-of-optimization}

\subsection{When is Optimization Possible Using Real Biological Data?}
Not all of the available data-sets are conducive to optimizing reduced models.
For example, consider the cerebellar Purkinje cell.
The Purkinje cells has a very large surface area (much of it the dendrites that support $~100,000$ synaptic inputs).
It consequently has a large capacitance and a low input resistance, and as such it demands a very large current stimulus to elicit a rheobase spike: $680pA$.
However, most reduced cells typically cannot exhibit such a large rheobase under any parameterization that otherwise looks like a neuron model.
The fact that an expansive dendritic tree is able to absorb so much somatically injected current may be difficult for a reduced model to capture.
Specifically, the upper limit for rheobase found in results was typically as $350-400pA$, but even this comes at the expense of sacrificing fit quality for all other electrophysiological features.
Consequently, optimized models of the Purkinje cell always failed to be biologically plausible.
The p-value of the $\chi^{2}$ statistic was always sufficiently low to reject the null hypothesis that such optimized models were representative of the biological data distribution.
Like the Purkinje cell, the Mitral cells of the main olfactory bulb also escaped successful model fitting.
These mitral cells also have high membrane capacitance $235pF$, and reduced models could not reproduce their features well.  
The Izhikevich model was achieved the lowest overall $\chi^{2}$ statistic for Purkinje cells and Mitral cells, being slightly more flexible than the AdEx or  conductance based models (see Tables \ref{tab:adex-allen} and \ref{tab:izhikevich-allen}).
In general, however, these reduced models may have been developed with smaller, more electronically compact cortical and hippocampal cells in mind.

\subsection{Conflicts between Experimental Features Constraining Optimization}
Feature values extracted from multiple data sets appeared to be in conflict for some cell types.
For example in the section below I show that the rheobase value was often incompatible with some passive electrophysiological feature values, such that good optimization could be achieved with one set or the other, but not both together.

\subsubsection{Tradeoff Patterns in Data-driven Tests in Subtheshold and at Threshold Electrical Properties}
\label{sec:rh_incomp}
Using data from the Allen Cell Types neuron with ID $471819401$,
I was able to optimize both AdEx and Izhkevich models, such that both models would agree with rheobase, time constant, resting membrane potential, and input resistance, experimental values. Some tradeoffs were needed in order match all of the values, as these features could not all be perfectly matched at once.
\begin{table}
\begin{center}
\begin{tabular}{|l|l|l|l|}
\toprule
Test name &   observations &    predictions & Z-Scores \\
\midrule
RheobaseTest         &       190.0 pA &      199.52 pA &     0.04 \\
TimeConstantTest     &        13.8 ms &        6.21 ms &     0.32 \\
RestingPotentialTest &       -77.5 mV &      -39.29 mV &     0.26 \\
InputResistanceTest  &  132.0 $M\Omega$ &  44.94 $M\Omega$ &     0.45 \\
\bottomrule
\end{tabular}
\caption[AdEx Model Fit Quality]{Predicted and observed features for neuron $471819401$ from the Allen Cell Types database, following optimization of the AdEx model against data from this neuron.
Other neurons showed similar optimization performance, and are shown in the Appendix.}
\label{tab:adex-allen}
\end{center}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}{|l|l|l|l|}
\toprule
{} &   observations &    predictions & Z-Scores \\
\midrule
RheobaseTest         &       190.0 pA &      190.48 pA &        0 \\
TimeConstantTest     &        13.8 ms &         1.9 ms &     0.94 \\
RestingPotentialTest &       -77.5 mV &      -70.65 mV &     0.03 \\
InputResistanceTest  &  132.0 $M\Omega$ &  25.47 $M\Omega$ &     0.74 \\
\bottomrule
\end{tabular}
\caption[AdEx Model Fit Quality]{Same as the Table \ref{tab:adex-allen} but for the Izhikevich model.}
\label{tab:izhikevich-allen}
\end{center}
\end{table}

%And different specimen id's For example: 482493761 id:
%Adex:
%\newline
%\begin{center}
%\begin{tabular}{|l|l|l|l|}
%\toprule
%Feature Name &   observations &               predictions & Z-Scores \\
%\midrule
%RheobaseTest         &        70.0 pA &                   73.4 pA &     0.04 \\
%TimeConstantTest     &        24.4 ms &  0.0029 ms &     9.32 \\
%RestingPotentialTest &       -71.6 mV &                 -49.76 mV &     0.13 \\
%InputResistanceTest  &  132.0 megaohm &             72.15 megaohm &     0.23 \\
%\bottomrule
%\end{tabular}
%\end{center}
%\end{table}


%Izhikevich:
%\begin{table}
%\begin{center}
%\begin{tabular}{|l|l|l|l|}
%\toprule
%{} &   observations &    predictions & Z-Scores \\
%\midrule
%RheobaseTest         &        70.0 pA &       71.19 pA &     0.01 \\
%TimeConstantTest     &        24.4 ms &        2.85 ms &     1.05 \\
%RestingPotentialTest &       -71.6 mV &      -55.05 mV &      0.1 \\
%InputResistanceTest  &  132.0 megaohm &  46.06 $M\Ohm$ &     0.43 \\
%\bottomrule
%\end{tabular}
%\end{center}
%\end{table}


%\begin{table}
\subsubsection{6239608801 AdEx}
The need to match the rheobase appeared to be interfering with the ability of the optimizers to match many other features.
The rheobase is essentially the knee of the FI curve.
An alternative strategy is to produce models that match the slope of the FI curve.
Here I show two out of $12$ examples demonstrating that that fitting models to the FISlope and rheobase only, leads to generally better agreement as there is less conflict between these two tests.
%\textbf{Model Parameters}
%\newline
%\begin{center}
%\resizebox{0.7\textwidth}{!}{
%\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|r|}
%\toprule
%{} &          cm &    v\_spike &    v\_reset &     %v\_rest &      tau\_m &         a &         b &   delta\_T &       tau\_w &   v\_thresh &  spike\_delta \\
%\midrule
%0 &  147.166079 & -45.027618 & -32.175811 & -51.521467 &  51.323969 &  1.787643 &  5.553571 &  4.143261 &  158.661633 & -25.749411 &    15.471554 \\
%\bottomrule
%\end{tabular}}
%\newline
%\end{center}
%\end{table}

\begin{table}
\begin{center}
\begin{tabular}{|l|l|l|l|}
\toprule
{} & observations &   predictions & Z-Scores \\
\midrule
FITest       &   0.18 Hz/pA &  0.18 Hz/pA &     0.01 \\
RheobaseTest &      70.0 pA &      70.26 pA &        0 \\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}{|l|r|}
\toprule
chi\_square &  0.000083 \\
p\_value    &  1.000000 \\
\bottomrule
\end{tabular}
\end{center}
\caption[Quality of Fit to Experimental Data]{Summary statistics of fit quality using AdEx model, when it is constrained against FITest, and Rheobase Test alone.
The very low $\chi^2$ statistic (and high p-value) indicate that there was no evidence that this optimized cell model produced behavior outside of the range of biological neurons of the same type, at least for the features examined here.}
\label{tab:chi2-p-1}
\end{table}

%\newline

\subsubsection{6239608801 Izhikevich}

%\newline
%\textbf{Model Parameters}
%\newline
%\begin{center}

%\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|}
%\toprule
%{} &           C &        k &         vr &         vt &      vPeak &        a &          b &          c &          d &  celltype \\
%\midrule
%0 &  190.848367 &  0.77007 & -65.461028 & -49.496538 &  31.461532 &  0.05877 &  13.916167 & -58.159122 &  38.738638 &         7 \\
%\bottomrule
%\end{tabular}}
%\end{center}


\begin{table}
\begin{center}
\begin{tabular}{|l|l|l|l|}
\toprule
Features & observations &   predictions & Z-Scores \\
\midrule
FITest       &   0.18 Hz/pA &  0.18 Hz/pA &        0 \\
RheobaseTest &      70.0 pA &      66.61 pA &     0.04 \\
\bottomrule
\end{tabular}
\end{center}
\begin{center}
\begin{tabular}{|l|r|}
\toprule
chi\_square &  0.00155 \\
p\_value    &  1.00000 \\
\bottomrule
\end{tabular}
\caption[Quality of Fit to Experimental Data]{Similar to Table \ref{tab:chi2-p-1}, but for Izhikevich model. Since two major model classes are better able to fit to FITest and Rheobase alone, it suggests that these two measurements might be less conflicted in models.
}
\end{center}
\end{table}


By ``good optimization" I mean that the optimized model exhibited behavior that was consistent with all of the features.
Models seemed to have particular difficulty in recapitulating an accurate fit for rheobase, while simultaneously satisfying the fitness criteria imposed by the time constant, input resistance, capacitance and resting membrane potential.
This was less problematic when using the slope of the FI curve as a feature, suggested that it was not spiking \emph{per se} that caused the problem.

This was also evident when working across datasets.
For example, when optimizing against data from both NeuroElectro and the Allen Cell types database, it was typically impossible to satisfy data-derived features from both sources simultaneously, even when the same nominal neuron type was being described.

%The l5pc model was pre-optimized to fit to spike times and F/I mainly, and so it should not necessarily be expected to fit other electrical characteristics of the cell. Only the rheobase test, and the time constant test seemed to fall within the range of biological plausibility. None the less, this model remains a useful benchmark for reduced neuronal models.
%It was desirable to include this extended range of Izhikevich model behavior
%However, as noted in the introductory material, it i 
%Previously I mentioned neuronal modelling competitions I have optimize every model against the same data sets in order to assess overall which model is better able to fit to diverse data sets.

%
%\begin{comment}
%\subsection{Neocortical Layer 4/5 Pyramidal Cell Test Suite}
%\subsection{%2a}
%Direct Quote: "widening of the spike shape, decrease of the firing rate and change in the interspike interval distribution". %All these single unit waveform shapes increased their width with temperature.\cite{goldin2017temperature}

%1a/b Is Optimization possible?
%       1a. Construction of tests from diverse experimental sources (I wrote the neuroelectro api and its use in neuronunit, and wrote the original Allen one, but you have put in work to create runnable tests from these and other sources).  This is in a sense a method, but you can still report that these tests are runnable, even outside of optimization.
%       1b. Simulated data tests of optimization.  What works?  What doesn’t?  Why (briefly, saving some for discussion)?  NeuroElectro vs Allen also belong here, and fits in with 1a.  You should talk about model means vs means of models (or whatever we are calling it) here, if you have the results for it or think you can in 3 weeks.  
       %You can talk about rippled error surfaces — this is such a deep technical detail that I wouldn’t spend a lot of time on it.  In other words it may be important but it will be almost impossible to follow even if written well.


%During optimization knowledge of error surfaces should not be mandatory but it can help to solidify good optimization outcomes.  Through human examination of resulting error surfaces, it was found that some of the novel test sets were not helpful to the optimization framework.  Interestingly some types of tests had a propensity to amplify errors originating from elsewhere.

% depended on current stimulus values that were not fixed between models, but instead where contingent on the changeable state of the model cell, this measurement was usually the derivative of membrane potential: $max(\frac{dV_{m}}{dt})/10$. For more on this see \ref{sec:Optimization Pitfalls} 
% duplication
%I found that some fraction of these new tests were because they depended on measured features relative to some other changeable measurement inside the cell usually $max(\frac{dV_{m}}{dt})/10.$ As I discuss in methods, had the propensity of amplifying errors that propogated from elsewhere. 
%This required both the extraction of novel features [EFEL: ISI, AHP-depth, adaption ratio etc.] on new data types types.

%This class was also acculated useful helpful methods such as retrieving default model parameters.
