
\section{Limitations of Optimization using Experimental Data}
\label{sec:limitations-of-optimization}

\subsection{When is Optimization Possible Using Real Biological Data?}
Not all of the available data-sets are conducive to optimizing reduced models.
For example, consider the cerebellar Purkinje cell.
The Purkinje cells has a very large surface area (much of it the dendrites that support $~100,000$ synaptic inputs).
It consequently has a large capacitance and a low input resistance, and as such it demands a very large current stimulus to elicit a rheobase spike: $680pA$.
However, most reduced cells typically cannot exhibit such a large rheobase under any parameterization that otherwise looks like a neuron model.
The fact that an expansive dendritic tree is able to absorb so much somatically injected current may be difficult for a reduced model to capture.
Specifically, the upper limit for rheobase found in results was typically as $350-400pA$, but even this comes at the expense of sacrificing fit quality for all other electrophysiological features.
Consequently, optimized models of the Purkinje cell always failed to be biologically plausible.
The p-value of the $\chi^{2}$ statistic was always sufficiently low to reject the null hypothesis that such optimized models were representative of the biological data distribution.
Like the Purkinje cell, the Mitral cells of the main olfactory bulb also escaped successful model fitting.
These mitral cells also have high membrane capacitance $235pF$, and reduced models could not reproduce their features well.  
The Izhikevich model was achieved the lowest overall $\chi^{2}$ statistic for Purkinje cells and Mitral cells, being slightly more flexible than the AdEx or  conductance based models.
In general, however, these reduced models may have been developed with smaller, more electronically compact cortical and hippocampal cells in mind.

\subsection{Conflicts between Experimental Features Constraining Optimization}
Feature values extracted from multiple data sets appeared to be in conflict for some cell types.
For example, the rheobase value was often incompatible with some passive electrophysiological feature values, such that good optimization could be achieved with one set or the other, but not both together.
By good optimization I mean that the optimized model exhibited behavior that was consistent with all of the features.
Models seemed to have particular difficulty in recapitulating an accurate fit for rheobase, while simultaneously satisfying the fitness criteria imposed by the time constant, input resistance, capacitance and resting membrane potential.
This was less problematic when using the slope of the FI curve as a feature, suggested that it was not spiking \emph{per se} that caused the problem.

This was also evident when working across datasets.
For example, when optimizing against data from both NeuroElectro and the Allen Cell types database, it was typically impossible to satisfy data-derived features from both sources simultaneously, even when the same nominal neuron type was being described.

%The l5pc model was pre-optimized to fit to spike times and F/I mainly, and so it should not necessarily be expected to fit other electrical characteristics of the cell. Only the rheobase test, and the time constant test seemed to fall within the range of biological plausibility. None the less, this model remains a useful benchmark for reduced neuronal models.
%It was desirable to include this extended range of Izhikevich model behavior
%However, as noted in the introductory material, it i 
%Previously I mentioned neuronal modelling competitions I have optimize every model against the same data sets in order to assess overall which model is better able to fit to diverse data sets.

%
%\begin{comment}
%\subsection{Neocortical Layer 4/5 Pyramidal Cell Test Suite}
%\subsection{%2a}
%Direct Quote: "widening of the spike shape, decrease of the firing rate and change in the interspike interval distribution". %All these single unit waveform shapes increased their width with temperature.\cite{goldin2017temperature}

%1a/b Is Optimization possible?
%       1a. Construction of tests from diverse experimental sources (I wrote the neuroelectro api and its use in neuronunit, and wrote the original Allen one, but you have put in work to create runnable tests from these and other sources).  This is in a sense a method, but you can still report that these tests are runnable, even outside of optimization.
%       1b. Simulated data tests of optimization.  What works?  What doesn’t?  Why (briefly, saving some for discussion)?  NeuroElectro vs Allen also belong here, and fits in with 1a.  You should talk about model means vs means of models (or whatever we are calling it) here, if you have the results for it or think you can in 3 weeks.  
       %You can talk about rippled error surfaces — this is such a deep technical detail that I wouldn’t spend a lot of time on it.  In other words it may be important but it will be almost impossible to follow even if written well.


%During optimization knowledge of error surfaces should not be mandatory but it can help to solidify good optimization outcomes.  Through human examination of resulting error surfaces, it was found that some of the novel test sets were not helpful to the optimization framework.  Interestingly some types of tests had a propensity to amplify errors originating from elsewhere.

% depended on current stimulus values that were not fixed between models, but instead where contingent on the changeable state of the model cell, this measurement was usually the derivative of membrane potential: $max(\frac{dV_{m}}{dt})/10$. For more on this see \ref{sec:Optimization Pitfalls} 
% duplication
%I found that some fraction of these new tests were because they depended on measured features relative to some other changeable measurement inside the cell usually $max(\frac{dV_{m}}{dt})/10.$ As I discuss in methods, had the propensity of amplifying errors that propogated from elsewhere. 
%This required both the extraction of novel features [EFEL: ISI, AHP-depth, adaption ratio etc.] on new data types types.

%This class was also acculated useful helpful methods such as retrieving default model parameters.
