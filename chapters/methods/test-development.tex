\subsection{Novel Data-Driven Tests for Model Optimization}
At the onset of this project, NeuronUnit contained a range of model validation tests, but these were inadequate for for optimization.
Most such tests were restricted to measurements of passive membrane properties or action potential waveforms.
However, the rich diversity of neuronal physiology is also reflected in the rate, timing, and sensitivity of patterns of action potentials.

As noted in Section \ref{sec:data-sources} there were two experimental data types, each of which was used to constrain models differently: raw data from which features were (re-)calculated, and pre-computed features as reported in the literature.
The distinction is important here because in the former case new feature extraction routines are required.
In order to developed tests based on these newly calculated features, I created an interface to the Allen Cell Types API; this allowed me to automatically create NeuronUnit tests parameterized by features extracted from the membrane potential traces available from the Allen Institute through that API.
In order to create the new NeuronUnit tests, one must query the Cell Types Database, impose a new organization on the data, extract relevant features, and convert model features for use with NeuronUnit tests.
A similar API was created in order to work with the Blue Brain data described in section \ref{sec:bluebrain-data}, so that both of these data sources could then guide model fitting.
These APIs and their use in generating NeuronUnit tests are documented in \url{https://github.com/fun-zoological-computing/BluePyOpt/blob/master/examples/bpo_nu_fusion/allen_efel_nu_deployed_tests_only-thesis.ipynb}

At this stage the range of tests available for optimization in NeuronUnit was still incomplete; the data was adequate, but several key features that distinguish one pattern of spiking from another were still missing. Therefore, I implemented another series of tests in NeuronUnit using the EFEL features \citep{EFEL} (section \ref{sec:efel}).
I developed the ability for all of the EFEL features to be calculated on NeuronUnit models, as well as a new test to compute the slope of the F-I curve.
I organized these tests into new "at threshold" and suprathreshold test suites, which included features such as
interspike-interval (ISI) statistics, after-hyperpolarization (AHP) depths, spike frequency adaption ratios, etc.

Adaptation in spike trains is commonly occurring. When fitting models to spike trains it is best to measure adaptation directly, and to use it as one of many equally weighted objective functions. Fitting models against adaptation directly is important for taking full advantage of the Adaptive Exponential model type.

%For example, I utilized an existing implementation of the spike frequency adaptation index.
% The adaptation index is calculated as follows \citep{EFEL}:

%\begin{equation}
%A = \frac{1}{N - k - 1} \sum_{i = k}^N \frac{isi_i - isi_{i-1}}{isi_i + isi_{i-1}}
%  = \frac{1}{N - k - 1} \sum_{i = k}^N \frac{tpeak_{i+1} - 2 tpeak_i + tpeak_{i-1}}{tpeak_{i+1} - tpeak_{i-1}}
%\end{equation}
%where the first $k$ peaks are skipped and:
%\begin{align}
%    \textrm{the interspike intervals:    } & isi_i = tpeak_{i+1} - tpeak_i,
%    \textrm{the number of peaks:    } & N.
%\end{align}
%The parameter \verbatim{spike skipf} is the fraction of skipped peaks, $k$ is %the minimum of \verbatim{spike skipf} times $N$ and \verbatim{max spike skip}.
  

In order to optimize reduced models, it was necessary to develop ``optimizer-friendly" implementations of these models.
As described in section \ref{sec:new-models}, I developed three different optimizer-friendly reduced models: the Izhikevich model (spanning seven dynamical regimes), the Adaptive Exponential Integrate and Fire (AdEx) model, and the GLIF model.
Additionally I created one slower single-compartment conductance-based model and I retrofitted a pre-existing multi-compartment conductance based model to make a broader array of comparisons across model types.

\subsection{Conversion Between Types and Model Exchange Across Threads}
Multi-core and or multi-threaded optimization requires that information about model properties be shareable across various processor threads.
However, some very common data types used in programming are not easily shareable between CPUs.
The release of Python 3.8 solved a subset of these problems, but this did not occur until late 2019 so I implemented an alternative scheme for cross-thread sharing of models.
I created a new NeuronUnit class ``Data Transport Container" (DTC), which can circulate essential data about model parameters and state variables between threads.
Models on one thread were collapsed into this container, shared between threads, and then reconstituted on a new thread.
This added a small amount of overhead, but this computational cost was negligible when measured against the gains of using multi-threaded processing.

Beyond the multi-threading context described above the DTC class constitutes the necessary expansion of Neuronunit model class needed to make optimization work. The DTC class enables the creation chromosomes from models to evaluate the fitness of any single chromosomes, and to convert chromosomes back to models, these types of conversions are essential to visualising Genetic Algorithm jobs.%, and they represent the difference between merely writing a one-off optimisation job versus making an actual optimisation package, ie re-usable software that promotes predictable code-patterns, and workflows. 

% The DTC type is able to evaluate most feature extraction algorithms on itself. Many users of NeuronUnit, are not performing optimization, such that placing these conversions in the Neuronunit base Model class does not make sense.

%  makes it possible to do many common genetic algorithm operations ``in place". It

%In addition to sharing essential information, across threads. The class DataTC containers role includes performing common in-place conversions and computations. 

%doing away with the DTC type would render most of the optimization code unusable.


% 

\subsection{Web Application for Optimization}
In order to both control optimization parameters and visualize optimization results, I also developed a web application that requires no programming skill to use, and allows a user to select among multiple cell-specific constraints, and multiple model types.
Once the user has specified enough parameters to define an optimization job, the job can launch, and return interactive results to the user after the optimization job completes (typically in minutes).
This is described in section \ref{sec:web-app}.