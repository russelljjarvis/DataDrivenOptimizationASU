\section{Future Work}
\subsection{Fixing Currents}
Here I identified a problem of contingent tests, which cause sometimes intractable defects in the error surface.
This could be solved by specifying all injected currents in advance and fitting directly to the entire FI curve.
Having been fit, features that are defined near rheobase (such as spike threshold) should then be computed at a pre-determined current.
%Despite there being negative consequences of this error for the signal sources tat guide optimization, there is still a mandate for models with different preferred currents to participate in testing. Preferred current searches are easily separable from Genetic Algorithms, meaning that a preferred current search can occur in an isolated part of a different algorithm where it will not act as the basis for electrical measurements. Over the course of a genetic algorithms search a fixed current can be applied to all models, allowing electrical measurements to be grounded to a stable value. Genetic algorithms can easily be nested inside each other, its easy to conceive of a situation, where an inner GA evaluates model fitness according to fixed currents, and an outer GA changes the fixed current that is used on each inner GA batch.
%The result of such a process should be a collection of optimized cells, that where obtained according to a different fixed current injection strength. %If one optimized model is clearly better, then two things about the model are revealed. What is the cell models preferred current, and what how well did it fit the tests? 
%This scheme is also different in that it treats current injection strength as a model parameter, and not a emergent feature of the model.

%cause of this finite precision error, 
%When model parameters are inserted into NeuroML cell model definitions, NeuroML encoded models become operational. These NeuroML encodings will if possible be uploaded into NeuroML-DB, where they will be more readily find-able by the neuron modelling community
% Such files can be used as network components, and they confidently utilized and exchanged, as such files represent a higher degree of rigor. Since there are two classes of model fits, some models are better suited fitted to network modelling and others are better suited to single cell modelling, this is because, by fitting cell models to FI curves, a lot of other realistic electrical behavior that is incompatible with the FI fit diminishes.

%At least for the Izhikevich, model links to the reference models, can also be provided.
\subsection{Model Exchange}
The NeuroML model exchange format \citep{gleeson2010neuroml} offers a portable, simulator agnostic, description of a neuron model including its parameters.
A logical next step is to capture the results of optimization and use them to specify these parameters, resulting in an optimized model that anyone can use.

\subsection{Embedding Models}
Reduced models could be especially valuable when embedded into a larger network that simulated a part of the brain
%, such as in the Blue Brain Project \cite{markram2006blue} and the Allen Institute \emph{V1} model 
The Allen Institute followed an approach like, encasing a "core" of biophysically accurate models inside a "shell" of surrounding, simple, fast and reduced GLIF models \citep{billeh2020systematic}.
%Results from this work suggests that pre-existing large scale brain simulations might be further improved by including a shell of AdEx or Izhikevich models.% The literature states only GLIF models, I am not proposing what they should do, only what I have read about.
%Izhikevich, GLIF, or Adaptive Exponential Integrate and Fire models.\\ 
Since almost all cortical neurons experience ``tonic" synaptic input, often originating from outside of the local circuit, such reduced models could be used to provide this input in a semi-realistic way, even as the neurons they target are simulated in greater detail.
Currently, this is often handled statistically rather than dynamically, by simulating some number of point processes to provide such input.
However, this makes strong assumptions about the nature of that input, and does not allow it to change dynamically the way it would if it originated from an actual neuronal or network simulation.
Reduced models can also be extended to include multiple compartments, allowing Local Field Potential (LFP) analysis to be included among the benefits of such an approach to network modeling.
The statistical approach also severs the link between cause and effect, and does not have any phenomenological relationship to known physics.
Finally, Izhikevitch and AdExp models are commonly utilized in neuromorphic spiking neural networks in artificial intelligence and biomedical modelling contexts, suggesting that their optimization in software could result in superior implementations of identified cell types in hardware.


%than generating only psuedo random timed inputs to synapses, 
%In the case of the Allen Institute Model, if the region of interest V1 is a "core" of realistic neurons. That is a kernel of realistic neurons encased by a shell of less realistic neurons. Inputs to V1 also come from the outer encasement of neurons. It is therefore of interest if these external GLIF models can or should be substituted with optimized Izhikivich and AdEx models, in case substiting GLIF for Adex results in an overall more realistic network simulation. In that case, even the external shell of simulation could experience a marginal improvement in accuracy. In network models there are benefits of reduced models over the use of a point process or a spike train surrogate.\\

% benefits: interpretability, transparent function, has current so contributes to LFP

%One of these benefits is that the firing of reduced neural models can be made to be causal, such that its spike times are not just what statistically matches missing models. Furthermore reduced models can still participate in networks, reduced models can become disconnected or participate in an dynamic assembly. Realistic levels of plasticity of the modelled network is more possible with included reduced models, than statistical surrogates of those models.


%Encasing a core of complex models inside a shell of simplified models mitigates a harmful edge effect. The problem is that simulations concern sub divisions of brain tissue and without intervention the act of making a subdivision severe synaptic inputs. All published highly detailed simulations to date, have necessitated the simulation of severed volumes of tissue, and this creates another problem to manage.\\