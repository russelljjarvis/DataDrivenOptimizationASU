\section{How Good was the Optimizer?}
%Three classes of experimental measurements were used to fit models in conjunction with genetic algorithms. These consisted of four groups of eight neuroelectro observations, and four groups of Allen electrical measurements from single cells. And also a group of  $14$ different EFEL measurements that were obtained by sampling Allen Brain sweep Data.

% It is worth noting that in both sets of measurements, the types of measurements that can guide optimization are significantly smaller subset of measurements of fitness criteria that can be evaluated on the final model.

%Final list of Elephant tests used to guide optimization: 
%\textbf{RheobaseTest}, InputResistanceTest, TimeConstantTest, CapacitanceTest, RestingPotentialTest.

When the optimizer is applied to the Izhikevich model for each of the four different classes of experimental cell types, it obtains solutions that are within the range of empirical variability.
Because the optimizer was not able to resolve conflicts between certain measurements, such as usually rheobase vs (time constant,input resistance, and membrane capacitance) performance is be even better if some of these conflicting features are removed.

In the single-compartment conductance-based model and in the AdEx model, even better solutions were obtained, but in these cases it was the need to match experimental input resistance that posed the greatest drag on solution quality.


%by all other fitness criteria in order for the optimizer to 
%\begin{comment}
%\end{comment}
%The EFEL measurements on Allen Data





%\item 

%\item Within a reasonable parameter range conductance based models are usually close to experimentally observed measurements.

%\section{A pattern to model fitting inability in Phenomenological Models.}
%* many reduced neural models are far from optimal at any point in parameter space. Optimizing does not significantly improve agreement. Optimizing does not bring model and experiment close to `Z=0`. There was some model to model variability however.

%\item There is an order of magnitude difference. Between agreement in Rheobase values between the conductance based models and the experimental models. 

%\end{itemize}

%\section{What does it mean.}
%\begin{itemize}

%\item  In methods I discussed an approach to verifying the optimizer.
%$-$ Specifically, we showed efficient optimizer convergence when constraints were derived from simulating experiments.

%When the optimizer setup is cogent because appropriate models and test combinations have been chosen, and because
%$N_{free_params} <= N_{constraints}$


%\item  In order to verify our approach we also re-implemented our code using BluePyOpts select best algorithm, and NSGA2.
%\end{itemize}

%Model constraint combinations give rise to differences in how correlated errors are during gene evolution. 

\section{Distinction of Optimization Approach From Other Approaches}
% This can be a fusion of your sections about multiobjective optimization, unit testing, and data integration (or whatever set of background items you think is fundamental to understanding the novelty of the work you have done).
There are several conceptual and technical differences between the work described here and what has been done previously.

First, I used a formal testing framework--normally used to evaluate model quality--to drive the optimization itself.
This means that we can evaluate not only technical performance of the optimizer, but the actual quality of the solutions, and compare these across models and cell types.
Other modeling efforts have employed data-driven testing in model development workflows, but all these efforts have been based on non-standard ‘in-house’ model types and execution environments.
By contrast, this work expands a pre-existing community driven, standardized model testing framework, NeuronUnit, so that model validation, optimization, and re-use is broadly applied.

Second, I unified many sources of experimental data and distinct feature types (subthreshold and suprathreshold) into a unified testing suite.
This has the potential to result in optimized models that reproduce not only specific patterns of spike but whole input/output transformations.
Reproducing these transformations is necessary if there is any hope for reduced models to be used in network models.

Third, I leveraged the large number of cortical neuron and neuronal network models are available in the standardized NeuroML format.
This allowed me evaluate the quality of existing models, identify their discrepancies against corresponding experimental data, and improve upon dozens of them in one stroke.
Although the Allen Institute for Brain Science modeling project and the Blue Brain project both rigorously analyzed their single cell models, to the best of my knowledge there has not been an overarching meta-analysis across different cell and network model sources.


%\section{Stuff that belongs in results or discussion; please move there}%  Generalized Linear Integrate and Fire model\cite{teeter2018generalized} or
% EVERYTHING IN THE SECTION BELOW HERE BELONGS IN THE RESULTS OR DISCUSSION
%We have used NeuronUnit to guide optimization by taking a flexible model types such as the Izhikevich model and then fitted these models using relevant experimental measurements inside our optimization frame work.

%As an example, select Best (IBEA) was used to optimize models in conjunction with data driven tests based on pooled data from NeuroElectro.org \cite{tripathy2014neuroelectro}. A variety of compact and fast single compartment models were used to explore model optimization. Figure 4 demonstrates test error at the beginning of the optimization process for models with randomly sampled parameters and the smaller error following optimization. Figure 5 shows the evolution of the error during the optimization process\\
%\\


%Optimized neuron models may vary from their experimental counterparts for several reasons. In the appendix generally, there are multiple tables that show that optimizing models with respect to the rheobase fits comes into conflict with minimizing with respect to input resistance. The solution to the optimization problem consists of two sets of model parameters, which can resolve this conflict differently. Examining the experimental data that these tests were derived from suddenly becomes important. By examining the data, we can see if the rheobase currents and the distributions of input resistance are bi-modal and uniformly distributed. If the data is treated as uni-modal, and the uni-modal mean is used to optimize then the model, then the model is not able to satisfy both constraints simultaneously. In this case, the measurements don’t correspond to neuron data, and the model can’t produce the artificial behavior. When comparing complex data and simple models we find that solutions are better represented using a combination of two optimization solutions.\\

