\section{Appropriate Optimization Constraints}
\subsection{Conflicting Optimization Constaints}
I identified multiple conflicts between features used for optimization.
In some cases, the conflicts may arise from limitations of the model, i.e. the model may lack the richness to lie at precisely the points in features space that some real neurons lie in.
However, I found that even for biophysically detailed neuron models, this limitation was sometimes still observed.
Thus, there must be some other source of these conflicts, which I identified as a conceptual pitfall in optimization: feature values computed from the mean of the corresponding features across many neurons (as in NeuroElectro) may not actually describe any real, single neuron (or in some cases any possible neuron). 
This was typical when combining the Rheobase, Input Resistance, and Time Constant, for example.

\subsection{Conflicts in Neuroelectro Measurements}
%%%
% 
%The NeuronUnit tests \emph{ThresholdTest},  \emph{SpikeHalfWidth}, and \emph{Spike Amplitude} were often incompatible with other tests due to the contingent discontinuity problem described in the previous section.
%By contrast, I experience few conflicts with \emph{FISlopeTest},  \emph{Capacitance},  \emph{Input Resistance}, and  \emph{Time Constant}.
%%%

%%
% Actually the two test sets above are compatible, the nuance is one set constitutes a reliable optimization guide, the other doesn't

% I found that you can still measure, 
%%  \emph{ThresholdTest},  \emph{SpikeHalfWidth}, and \emph{Spike Amplitude} after optimizing with the reliable guides and get satisfactory results for those measurements, but I anticipated that would confuse everyone too much.

% I did not want ambiguity the quality of fits on measurements that did not participate in guiding optimization.

% it is much easier to explain the quality of fits for metrics that did participate in optimization.


Membrane Time Constant measurements were consistently harder to use for guiding optimization, being incompatible with other features in almost all model types (including conductance based models, reduced models, and including all data types (NeuroElectro data and Allen Cell Types single experiment data).
This value is proportional to cell surface area, and it may be that cells taken from, for example, slices of different thicknesses have different capacitances but that this has minimal impact on other measurements.
Alternatively, most capacitance measurements could be in error due to recording pipette capacitance artifacts.
Regardless, when the membrane time constant was not included, optimized models were still able to behave in most other respects like their experimental counterparts

As discussed in section \ref{sec:parallel-rheobase} rheobase is strictly defined as the minimum current injection to evoke exactly one spike.
It does not fully define the FI curve, and there are an infinite number of FI curves that contain the points $(Rheobase^-, 0)$ and $(Rheobase^+, >0)$.

%%%
% I am not sure if I show this.
% I have (FIcurve + Rheobase)
% and I have (Rheobase+familiar tests)
%
% Actually maybe you are right.
% I had not thought about it in this way.
%%

Interestingly, if selecting only one suprathreshold feature to pair in optimization with the remaining physiological features, the FI slope was a better fit than the rheobase.
It may be that by considering the whole FI curve in optimization counter-intuitively makes optimization more flexible by allowing small misses on matching the rheobase in exchange for a better overall match to the remaining suprathreshold spike counts.

\subsection{Sufficient Optimization Constraints}
Avoiding conflict constraints, which tests are minimally sufficient to produce good optimization results?
Tests that worked within optimization:
Via \emph{Elephant} toolchain: FITests, Rheobase, Capacitance, Input Resistance, Time Constant, Resting Membrane Potential.
Via. 

\cite{druckmann2007novel} optimized neuron models using only suprathreshold stimuli by considering (1) spike rate; (2) an accommodation index; (3) latency to first spike;(4) average AP overshoot; (5) average depth of after hyperpolarization (AHP); and (6) average AP width.
However, when optimizing reduced neuron models, I found that the those 6 features measurements were insufficient for optimization, and additional constraints were required.
Overall, I found that the following features from the EFEL library were sufficient:
\begin{enumerate}
\item AHP-depth
\item all-ISI-values
\item Spikecount %$ (similar to rate)
\item adaptation-index
\item mean-AP-amplitude
\item min-voltage-between-spikes
\item minimum-voltage
\item peak-voltage
\item spike-half-width
\item time-to-first-spike
\item time-to-last-spike
\item voltage-base
\end{enumerate}

%\subsection{Exploting the FI Curve}
%There is visibly almost perfect  agreement between simulated and experiments and the optimized models, in the passive experimental conditions, and a close match for the spiking model behavior. There was a standard suite of tests if only spike-half-width, not spike-base-width. The Izhikevich models width as thus free to vary at the base, take that into account when eye balling the two graphs and you can see why almost binary match. EFEL does achieve spike width binary matching because it uses both half-width, and base-width. If you look at the last cells you can see I take a correlation matrix of the optimizers errors over its history. The idea is if it's normalized then I can sum the whole matrix and get a single scaler number to show how uncorrelated both error sets are over the GA evolution. 

%It was found that the elephant/neuroelectro-suite of NU tests don't fully constrain the spike width at the base of neuron action potential waveform. Since the base of the waveform was unconstrained, it was free to vary, half-spike-width is constrained, it is more appropriate to talk about variance explained of the spike snippet. $variance explained>0.95$ is a useful heuristic. Allowing some margin acknowledges that we shouldn't assume we have represented all waveform features that can vary. If you want $variance explained==1$   
%you could optimize using a variance explained 
%cost function, but we don't want to do that.