
    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}
    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for grffile with XeLaTeX
    \def\Gread@@xetex#1{%
      \IfFileExists{"\Gin@base".bb}%
      {\Gread@eps{\Gin@base.bb}}%
      {\Gread@@xetex@aux#1}%
    }
    \makeatother

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    
    
    

    
    To make optimization of reduced models tractable it was important to
evaluate the feasibility of optimizing with established model
implementations. Despite an abundance of choices in the simple modelling
ecosystem. For some classes of model a feasabile choice of
implementation did not always exist and it was easier to re-implement
several models. Two models I re-implemented for performance reasons were
the Adaptive Exponential Integrate and fire Model, and also the IZHI
model. In the work below, I profile existing model implementations, and
justify the reasons for re-implementing.

    \begin{Verbatim}[commandchars=\\\{\}]
/home/user/anaconda3/lib/python3.7/site-packages/airspeed/\_\_init\_\_.py:505:
FutureWarning: Possible nested set at position 8
  KEYVALSEP = re.compile(r'[ \textbackslash{}t]*:[[ \textbackslash{}t]*(.*)\$', re.S)
    \end{Verbatim}

    Below I have implemented a python integrator for the Adaptive
Exponential Integrate and fire model. This solver lead to faster
evaluations of current injection experiments. The integrator I developed
had a \texttt{\textgreater{}0mV} spiked when evaluated at default
parameter values.

This is in contrast to the brian2/neuraldynamics AdExp model, which took
between 2 or 3 times longer to find a rheobase current injection value
{[}2\emph{total-3}total{]}. However the slowness is not caused by the
simulation backend (brian2 which is relatively fast and efficient). The
slow down is caused by the way the model is defined. Specifically the
model is defined in a middle code layer neurodynamics. Presumably there
were good reasons why author of neural dynamics chose a model behavior
with spiking below 0mV. This is not technically wrong, but it violates
assumptions in the neuronal model feature extraction protocol. The
default spiking behavior, looks odd, and it is simply this poor model
definition that is causing a slower optimizer performance. The optimizer
takes an unusual waveform shape, and searches for longer in distant
parameter regions to find a good fit.

Before JIT compilation: Time taken to find Rheobase 7.0 seconds. After
JIT compilation: 4.0

Brian2 Time taken to find Rheobase: 4.40 Brian2 Time taken to find
Rheobase (parallel): 3.976

The evaluation times between Brian2 JIT and the custom written
integrator are similar. Both have average runs of 4 seconds, however the
spike shapes coming from the custom written code look more realistic
under default parameters.

\href{https://github.com/russelljjarvis/neuronunit/blob/master/neuronunit/unit_test/druckman_tests.ipynb}{Link}

    \hypertarget{bluff-test-to-compile-jit-only}{%
\section{Bluff test to compile JIT
only}\label{bluff-test-to-compile-jit-only}}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'cm': 281.0, 'v\_spike': -40.0, 'v\_reset': -70.6, 'v\_rest': -70.6, 'tau\_m':
9.3667, 'a': 4.0, 'b': 1.0805, 'delta\_T': 2.0, 'tau\_w': 144.0, 'v\_thresh':
-50.4, 'spike\_delta': 30.0, 'e\_rev\_E': -60.0, 'C': 60.0\}
time taken on block 24.234534740447998
    \end{Verbatim}

    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{backend_check_files/backend_check_4_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{jit-enabled-real-timed-test}{%
\section{JIT enabled real timed
test}\label{jit-enabled-real-timed-test}}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'cm': 281.0, 'v\_spike': -40.0, 'v\_reset': -70.6, 'v\_rest': -70.6, 'tau\_m':
9.3667, 'a': 4.0, 'b': 1.0805, 'delta\_T': 2.0, 'tau\_w': 144.0, 'v\_thresh':
-50.4, 'spike\_delta': 30.0, 'e\_rev\_E': -60.0, 'C': 60.0\}
time taken on block 3.3625197410583496
    \end{Verbatim}

    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{backend_check_files/backend_check_6_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
251 ms ± 5.02 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)
240 ms ± 11.1 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)
223 ms ± 12.5 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
922 ms ± 12.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
    \end{Verbatim}

    Compare parallel to serial speeds, and accuracy

    Below is the Brian2/NeuralDynamics AdExp model. Inorder to make the
spike height greater than 0mV it was easier to schedule waveform
modifications that occur straight after the the brian2 simulation, and
can be considered part of the wider simulation code. In post-processing
the waveform data type is a Neo Wave form object that is artificially
shifted above 0mV using code. The code takes additional time to complete
the algorithm of determining rheobase and displaying results. The time
of this model is deterimant on multiple factors, as discussed elsewhere,
execution time is not uniform across model parameterizations. Models
with multispiking behavior will take longer to solve.

Simulation times for this model vary, dramatically possibly because of
lazy evaluation, the simulation times may vary according to what else
you are running on your computer.

Not all models experience a speed up when executed in parallel, however
this model was faster in the parallel Rheobase determination algorithm.

Some common times are:3.92,6.75,4.48,5.17.

    \begin{Verbatim}[commandchars=\\\{\}]
\{'ADAPTATION\_TIME\_CONSTANT\_tau\_w': 100.0, 'ADAPTATION\_VOLTAGE\_COUPLING\_a': 0.5,
'FIRING\_THRESHOLD\_v\_spike': -30.0, 'MEMBRANE\_RESISTANCE\_R': 0.140625,
'MEMBRANE\_TIME\_SCALE\_tau\_m': 4.0625, 'RHEOBASE\_THRESHOLD\_v\_rh': -40.625,
'SHARPNESS\_delta\_T': 1.0, 'SPIKE\_TRIGGERED\_ADAPTATION\_INCREMENT\_b': 7.0,
'V\_RESET': -57.375, 'V\_REST': -105.0, 'b': 0.09, 'C': 1.0, 'peak\_v':
0.034999999999999996\}
time taken on block 10.91267204284668
\{'ADAPTATION\_TIME\_CONSTANT\_tau\_w': 100.0, 'ADAPTATION\_VOLTAGE\_COUPLING\_a': 0.5,
'FIRING\_THRESHOLD\_v\_spike': -30.0, 'MEMBRANE\_RESISTANCE\_R': 0.140625,
'MEMBRANE\_TIME\_SCALE\_tau\_m': 4.0625, 'RHEOBASE\_THRESHOLD\_v\_rh': -40.625,
'SHARPNESS\_delta\_T': 1.0, 'SPIKE\_TRIGGERED\_ADAPTATION\_INCREMENT\_b': 7.0,
'V\_RESET': -57.375, 'V\_REST': -105.0, 'b': 0.09, 'C': 1.0, 'peak\_v':
0.034999999999999996\}
time taken on block 6.811577081680298
\{'ADAPTATION\_TIME\_CONSTANT\_tau\_w': 100.0, 'ADAPTATION\_VOLTAGE\_COUPLING\_a': 0.5,
'FIRING\_THRESHOLD\_v\_spike': -30.0, 'MEMBRANE\_RESISTANCE\_R': 0.140625,
'MEMBRANE\_TIME\_SCALE\_tau\_m': 4.0625, 'RHEOBASE\_THRESHOLD\_v\_rh': -40.625,
'SHARPNESS\_delta\_T': 1.0, 'SPIKE\_TRIGGERED\_ADAPTATION\_INCREMENT\_b': 7.0,
'V\_RESET': -57.375, 'V\_REST': -105.0, 'b': 0.09, 'C': 1.0, 'peak\_v':
0.034999999999999996\}
time taken on block 5.215756893157959
\{'ADAPTATION\_TIME\_CONSTANT\_tau\_w': 100.0, 'ADAPTATION\_VOLTAGE\_COUPLING\_a': 0.5,
'FIRING\_THRESHOLD\_v\_spike': -30.0, 'MEMBRANE\_RESISTANCE\_R': 0.140625,
'MEMBRANE\_TIME\_SCALE\_tau\_m': 4.0625, 'RHEOBASE\_THRESHOLD\_v\_rh': -40.625,
'SHARPNESS\_delta\_T': 1.0, 'SPIKE\_TRIGGERED\_ADAPTATION\_INCREMENT\_b': 7.0,
'V\_RESET': -57.375, 'V\_REST': -105.0, 'b': 0.09, 'C': 1.0, 'peak\_v':
0.034999999999999996\}
time taken on block 5.193753480911255
\{'ADAPTATION\_TIME\_CONSTANT\_tau\_w': 100.0, 'ADAPTATION\_VOLTAGE\_COUPLING\_a': 0.5,
'FIRING\_THRESHOLD\_v\_spike': -30.0, 'MEMBRANE\_RESISTANCE\_R': 0.140625,
'MEMBRANE\_TIME\_SCALE\_tau\_m': 4.0625, 'RHEOBASE\_THRESHOLD\_v\_rh': -40.625,
'SHARPNESS\_delta\_T': 1.0, 'SPIKE\_TRIGGERED\_ADAPTATION\_INCREMENT\_b': 7.0,
'V\_RESET': -57.375, 'V\_REST': -105.0, 'b': 0.09, 'C': 1.0, 'peak\_v':
0.034999999999999996\}
time taken on block 5.341148614883423
\{'ADAPTATION\_TIME\_CONSTANT\_tau\_w': 100.0, 'ADAPTATION\_VOLTAGE\_COUPLING\_a': 0.5,
'FIRING\_THRESHOLD\_v\_spike': -30.0, 'MEMBRANE\_RESISTANCE\_R': 0.140625,
'MEMBRANE\_TIME\_SCALE\_tau\_m': 4.0625, 'RHEOBASE\_THRESHOLD\_v\_rh': -40.625,
'SHARPNESS\_delta\_T': 1.0, 'SPIKE\_TRIGGERED\_ADAPTATION\_INCREMENT\_b': 7.0,
'V\_RESET': -57.375, 'V\_REST': -105.0, 'b': 0.09, 'C': 1.0, 'peak\_v':
0.034999999999999996\}
time taken on block 5.382237911224365
\{'ADAPTATION\_TIME\_CONSTANT\_tau\_w': 100.0, 'ADAPTATION\_VOLTAGE\_COUPLING\_a': 0.5,
'FIRING\_THRESHOLD\_v\_spike': -30.0, 'MEMBRANE\_RESISTANCE\_R': 0.140625,
'MEMBRANE\_TIME\_SCALE\_tau\_m': 4.0625, 'RHEOBASE\_THRESHOLD\_v\_rh': -40.625,
'SHARPNESS\_delta\_T': 1.0, 'SPIKE\_TRIGGERED\_ADAPTATION\_INCREMENT\_b': 7.0,
'V\_RESET': -57.375, 'V\_REST': -105.0, 'b': 0.09, 'C': 1.0, 'peak\_v':
0.034999999999999996\}
time taken on block 5.1901795864105225
\{'ADAPTATION\_TIME\_CONSTANT\_tau\_w': 100.0, 'ADAPTATION\_VOLTAGE\_COUPLING\_a': 0.5,
'FIRING\_THRESHOLD\_v\_spike': -30.0, 'MEMBRANE\_RESISTANCE\_R': 0.140625,
'MEMBRANE\_TIME\_SCALE\_tau\_m': 4.0625, 'RHEOBASE\_THRESHOLD\_v\_rh': -40.625,
'SHARPNESS\_delta\_T': 1.0, 'SPIKE\_TRIGGERED\_ADAPTATION\_INCREMENT\_b': 7.0,
'V\_RESET': -57.375, 'V\_REST': -105.0, 'b': 0.09, 'C': 1.0, 'peak\_v':
0.034999999999999996\}
time taken on block 5.155378580093384
5.47 s ± 553 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
\{'ADAPTATION\_TIME\_CONSTANT\_tau\_w': 100.0, 'ADAPTATION\_VOLTAGE\_COUPLING\_a': 0.5,
'FIRING\_THRESHOLD\_v\_spike': -30.0, 'MEMBRANE\_RESISTANCE\_R': 0.140625,
'MEMBRANE\_TIME\_SCALE\_tau\_m': 4.0625, 'RHEOBASE\_THRESHOLD\_v\_rh': -40.625,
'SHARPNESS\_delta\_T': 1.0, 'SPIKE\_TRIGGERED\_ADAPTATION\_INCREMENT\_b': 7.0,
'V\_RESET': -57.375, 'V\_REST': -105.0, 'b': 0.09, 'C': 1.0, 'peak\_v':
0.034999999999999996\}
time taken on block 4.488519191741943
    \end{Verbatim}

    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{backend_check_files/backend_check_12_10.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
272 ms ± 66.5 µs per loop (mean ± std. dev. of 2 runs, 1 loop each)
303 ms ± 10.9 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)
342 ms ± 11 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)
    \end{Verbatim}

    The next model to be evaluated is the NEURON Izhi model. The NEURON Izhi
model has various draw backs. 1. It depends on an external file which
must be recompiled each time this project is recreated. 2. The build
environment of NEURON is non-trivial, and only a super dedicated NEURON
modeller would install it on their system. Any performance advantage of
using NEURON investment does not exceed the installation cost of
installing the program. 3. The model implementation code is less
generalizable than than the published Izhi model itself. Where the
standard NEURON-NeuroML code only covers the Regular-Spiking model *
This is likely due to a name space conflict between Capacitance. Neuron
has a `capacitive' mechanism inside modelled Neurons, this particular
model has section capacitance as well as an introduced capacitive term
inside a C-compiled mechanism. Both contribute to a the membrane
potential calculation. * The NEURON Izhi model took 78 seconds to find a
Rheobase current injection value.

    \begin{Verbatim}[commandchars=\\\{\}]
<class 'neuronunit.models.reduced.ReducedModel'>
<neuronunit.models.backends.neuron.NEURONBackend object at 0x7f6d41088c90>
\{'k': 0.0007, 'vr': -60.0, 'vt': -40.0, 'vpeak': 35.0, 'a': 0.03, 'b': -0.002,
'c': -50.0, 'd': 0.1, 'C': 0.0001\}
<class 'neuronunit.models.reduced.ReducedModel'>
<neuronunit.models.backends.neuron.NEURONBackend object at 0x7f6d42382b90>
time taken on block 39.3937041759491
    \end{Verbatim}

    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{backend_check_files/backend_check_14_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\begin{Verbatim}[commandchars=\\\{\}]
array(51.79367065) * pA
\end{Verbatim}
\end{tcolorbox}
        
    \hypertarget{parallel-rheobase}{%
\section{Parallel Rheobase}\label{parallel-rheobase}}

Algorithm was able to speed up this slow NEURON unit code. 73/19
represents a substantial speed up. of about 3.8. This is consistent with
previous work

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\begin{Verbatim}[commandchars=\\\{\}]
\{'value': array(51.79317142) * pA\}
\end{Verbatim}
\end{tcolorbox}
        
    The forward Euler python IZhi model is very fast. The forward euler
implementation utilized Numba JIT. Rheobase is found in under a second,
and in many cases close 0.5 seconds. This represents a very dramatic
speed up.

Unlike the NEURON NeuroML implementation of the izhikitich equation,
this implementation is just as generalizable as the original MATLAB
implementation of the izhikitich model.

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\begin{Verbatim}[commandchars=\\\{\}]
"125.0\textbackslash{}n\{'C': 125.0, 'a': 0.02, 'b': 6.5, 'c': -50.0, 'd': 80.0, 'k': 1.15,
'vPeak': 37.5, 'vr': -65.5, 'vt': -45.0, 'dt': 0.01, 'Iext': []\}\textbackslash{}ntime taken on
block 0.6859951019287109 \textbackslash{}n3.3 ms +- 9.79 us per loop (mean +- std. dev. of 2
runs, 100 loops each)\textbackslash{}n3.32 ms +- 30.9 us per loop (mean +- std. dev. of 2 runs,
100 loops each)\textbackslash{}n3.19 ms +- 10.9 us per loop (mean +- std. dev. of 2 runs, 100
loops each)\textbackslash{}n\{'C': 125.0, 'a': 0.02, 'b': 6.5, 'c': -50.0, 'd': 80.0, 'k': 1.15,
'vPeak': 37.5, 'vr': -65.5, 'vt': -45.0, 'dt': 0.01, 'Iext': array([0., 0., 0.,
{\ldots}, 0., 0., 0.])\}\textbackslash{}ntime taken on block 0.6351408958435059 \textbackslash{}n"
\end{Verbatim}
\end{tcolorbox}
        
    \hypertarget{python-versions-of-single-compartment-conducance-model.}{%
\section{Python versions of single compartment Conducance
model.}\label{python-versions-of-single-compartment-conducance-model.}}

Conductance based chanels models took approximately the same amount of
time to evaluate the Rheobase search algorithm as the python
implementation.

This problem in the default parameterization of the python model was
later located in the scale or units of capacitance, if default
capacitance parameterization is multiplied by 100.0 the problem goes
away.

    \begin{Verbatim}[commandchars=\\\{\}]
\{'E\_L': -68.9346, 'E\_K': -90.0, 'E\_Na': 120.0, 'g\_L': 0.1, 'g\_K': 36.0, 'g\_Na':
200.0, 'C\_m': 1.0, 'vr': -68.9346, 'Vr': -68.9346, 'cm': 100.0\}
time taken on block 12.626658201217651
    \end{Verbatim}

    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{backend_check_files/backend_check_22_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\begin{Verbatim}[commandchars=\\\{\}]
array(1.40762329) * pA
\end{Verbatim}
\end{tcolorbox}
        
    \hypertarget{neuron-versions-of-single-compartment-conducance-model.}{%
\section{NEURON versions of single compartment Conducance
model.}\label{neuron-versions-of-single-compartment-conducance-model.}}

Conductance based chanels models took approximately the same amount of
time to evaluate the Rheobase search algorithm as the python
implementation.

The NEURON implementation was slightly faster, and the default
parameterization of the model lacked ``ringing'', or below threshold
oscillations that the Python ODE version had under default conditions.

This problem in the default parameterization of the python model was
later located in the scale or units of capacitance, if default
capacitance parameterization is multiplied by 100.0 the problem goes
away.

    \begin{Verbatim}[commandchars=\\\{\}]
\{'E\_L': -68.9346, 'E\_K': -90.0, 'E\_Na': 120.0, 'g\_L': 0.1, 'g\_K': 36.0, 'g\_Na':
200.0, 'C\_m': 1.0, 'vr': -68.9346, 'Vr': -68.9346\}
time taken on block 8.573923826217651
    \end{Verbatim}

    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{backend_check_files/backend_check_26_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
112.5 pA
\{'value': array(1.40645904) * pA\}
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
time step 0 / 64
time step 0 / 64
time step 0 / 64
time step 0 / 64
time step 0 / 64
time step 0 / 64
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'El\_reference': -0.07016548013687134, 'C': 3.990452661875942e-10,
'init\_threshold': 0.02964956889477108, 'th\_inf': 0.02964956889477108,
'spike\_cut\_length': 109.5, 'init\_voltage': -35.0, 'R\_input': 910258965.9792937\}
0.62137434895311 mV 2.7368671294272984 mV
0.0 mV -0.065 mV
0.31069759691841936 mV 1.33594806210705 mV
0.15535922090107404 mV 0.6354885284469255 mV
0.07769003289240137 mV 0.28525876161686337 mV
0.07769003289240137 mV 0.28525876161686337 mV
time taken on block 0.23476457595825195
    \end{Verbatim}

    
    \begin{verbatim}
<Figure size 432x288 with 0 Axes>
    \end{verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{backend_check_files/backend_check_28_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
112.5 pA
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
time step 0 / 64
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
0.0 mV -0.065 mV
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
time step 0 / 64
time step 0 / 64
time step 0 / 64
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
0.12659285497193595 mV 0.5057737999913468 mV
0.3797368751483505 mV 1.6472634104004382 mV
0.2531648650601433 mV 1.0765186051958928 mV
\{'value': array(183.33333333) * pA\}
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\begin{Verbatim}[commandchars=\\\{\}]
array(112.5) * pA
\end{Verbatim}
\end{tcolorbox}
        
            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\begin{Verbatim}[commandchars=\\\{\}]
'\textbackslash{}nfrom neuronunit.optimisation.brian\_glif\_model\_parameters import
HH\_attrs\textbackslash{}nsimple\_cell = ephys.models.ReducedCellModel(\textbackslash{}n
name=\textbackslash{}'simple\_cell\textbackslash{}',\textbackslash{}n        params=HH\_attrs,backend="GLIF")
\textbackslash{}nsimple\_cell.backend = "GLIF"\textbackslash{}nmodel = simple\_cell\textbackslash{}n\textbackslash{}nmodel.attrs =
\{k:np.mean(v) for k,v in model.params.items() \}\textbackslash{}n\textbackslash{}ndtc =
model.model\_to\_dtc()\textbackslash{}ndtc.attrs = model.attrs \textbackslash{}n\textbackslash{}nvm,plt,pre\_model =
inject\_and\_plot\_model(dtc,plotly=False)\textbackslash{}nplt.show()\textbackslash{}n'
\end{Verbatim}
\end{tcolorbox}
        
    \begin{Verbatim}[commandchars=\\\{\}]
time step 0 / 39
time step 0 / 39
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
0.017240506310425608 mV -0.08583939747094235 mV
0.017240506310425608 mV -0.08583939747094235 mV
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{backend_check_files/backend_check_32_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    % Add a bibliography block to the postdoc
    
    
    
\end{document}
